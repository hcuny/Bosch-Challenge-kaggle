{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def station32_34_tr():\n",
    "    \n",
    "    STATIONS = ['S32', 'S33', 'S34']\n",
    "    train_date_part = pd.read_csv('Y://Data//Kaggle//bosch//train_date//train_date.csv')\n",
    "    date_cols = train_date_part.drop('Id', axis=1).count().reset_index().sort_values(by=0, ascending=False)\n",
    "    date_cols['station'] = date_cols['index'].apply(lambda s: s.split('_')[1])\n",
    "    date_cols = date_cols[date_cols['station'].isin(STATIONS)]\n",
    "    date_cols = date_cols.drop_duplicates('station', keep='first')['index'].tolist()\n",
    "    print(date_cols)\n",
    "    train_date = pd.read_csv('Y://Data//Kaggle//bosch//train_date//train_date.csv', usecols=['Id'] + date_cols)\n",
    "    print(train_date.columns)\n",
    "    train_date.columns = ['Id'] + STATIONS\n",
    "    for station in STATIONS:\n",
    "        train_date[station] = 1 * (train_date[station] >= 0)\n",
    "    response = pd.read_csv('Y://Data//Kaggle//bosch//train_numeric.csv', usecols=['Id'])\n",
    "    print(response.shape)\n",
    "    train = response.merge(train_date, how='left', on='Id')\n",
    "    # print(train.count())\n",
    "    #train.head(3)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def station32_34_te():\n",
    "    \n",
    "    STATIONS = ['S32', 'S33', 'S34']\n",
    "    test_date_part = pd.read_csv('Y://Data//Kaggle//bosch//test_date.csv')\n",
    "    date_cols = test_date_part.drop('Id', axis=1).count().reset_index().sort_values(by=0, ascending=False)\n",
    "    date_cols['station'] = date_cols['index'].apply(lambda s: s.split('_')[1])\n",
    "    date_cols = date_cols[date_cols['station'].isin(STATIONS)]\n",
    "    date_cols = date_cols.drop_duplicates('station', keep='first')['index'].tolist()\n",
    "    print(date_cols)\n",
    "    test_date = pd.read_csv('Y://Data//Kaggle//bosch//test_date.csv', usecols=['Id'] + date_cols)\n",
    "    print(test_date.columns)\n",
    "    test_date.columns = ['Id'] + STATIONS\n",
    "    for station in STATIONS:\n",
    "        test_date[station] = 1 * (test_date[station] >= 0)\n",
    "    response = pd.read_csv('Y://Data//Kaggle//bosch//test_numeric.csv', usecols=['Id'])\n",
    "    print(response.shape)\n",
    "    test = response.merge(test_date, how='left', on='Id')\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr=station32_34_tr()\n",
    "tr.to_csv('Y://Data//Kaggle//bosch//station_feature_tr.csv',index=False)\n",
    "te=station32_34_te()\n",
    "te.to_csv('Y://Data//Kaggle//bosch//station_feature_te.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#very inspiring features, start time & end time etc.,  \n",
    "def magic_feature():\n",
    "\n",
    "    DATA_DIR = \"Y://Data//Kaggle//bosch\"\n",
    "\n",
    "    ID_COLUMN = 'Id'\n",
    "    TARGET_COLUMN = 'Response'\n",
    "\n",
    "    SEED = 0\n",
    "    CHUNKSIZE = 51500\n",
    "    NROWS_TR = 1183747\n",
    "    NROWS_TE = 1183748\n",
    "\n",
    "    TRAIN_NUMERIC = \"{0}/train_numeric.csv\".format(DATA_DIR)\n",
    "    TRAIN_DATE = \"{0}/train_date.csv\".format(DATA_DIR)\n",
    "\n",
    "\n",
    "    TEST_NUMERIC = \"{0}/test_numeric.csv\".format(DATA_DIR)\n",
    "    TEST_DATE = \"{0}/test_date.csv\".format(DATA_DIR)\n",
    "\n",
    "\n",
    "    FILENAME = \"etimelhoods\"\n",
    "\n",
    "    train = pd.read_csv(TRAIN_NUMERIC, usecols=[ID_COLUMN, TARGET_COLUMN], nrows=NROWS_TR)\n",
    "    test = pd.read_csv(TEST_NUMERIC, usecols=[ID_COLUMN], nrows=NROWS_TE)\n",
    "\n",
    "    train[\"StartTime\"] = -1\n",
    "    test[\"StartTime\"] = -1\n",
    "    train[\"EndTime\"]= -1\n",
    "    test[\"EndTime\"]= -1\n",
    "    train[\"Duration\"]=-1\n",
    "    test[\"Duration\"]=-1\n",
    "\n",
    "\n",
    "    #date process\n",
    "    #nrows = 0\n",
    "    for tr in pd.read_csv(TRAIN_DATE, chunksize=CHUNKSIZE):\n",
    "\n",
    "        feats = np.setdiff1d(tr.columns, [ID_COLUMN])\n",
    "        stime_tr = tr[feats].min(axis=1).values #min value of col\n",
    "        etime_tr = tr[feats].max(axis=1).values\n",
    "        du_tr=etime_tr - stime_tr\n",
    "\n",
    "\n",
    "        train.loc[train.Id.isin(tr.Id), 'StartTime'] = stime_tr\n",
    "        train.loc[train.Id.isin(tr.Id), 'EndTime'] = etime_tr\n",
    "        train.loc[train.Id.isin(tr.Id), 'Duration'] = du_tr\n",
    "\n",
    "\n",
    "\n",
    "        #nrows += CHUNKSIZE\n",
    "\n",
    "        #if nrows >= NROWS:\n",
    "            #break \n",
    "            \n",
    "    for  te in pd.read_csv(TEST_DATE, chunksize=CHUNKSIZE):\n",
    "\n",
    "        feats = np.setdiff1d(tr.columns, [ID_COLUMN])\n",
    "\n",
    "        stime_te = te[feats].min(axis=1).values\n",
    "        etime_te = te[feats].max(axis=1).values\n",
    "        du_te=etime_te - stime_te\n",
    "\n",
    "        test.loc[test.Id.isin(te.Id), 'StartTime'] = stime_te\n",
    "        test.loc[test.Id.isin(te.Id), 'EndTime'] = etime_te\n",
    "        test.loc[test.Id.isin(te.Id), 'Duration'] = du_te\n",
    "\n",
    "\n",
    "#        nrows += CHUNKSIZE\n",
    "#        if nrows >= NROWS:\n",
    "#            break\n",
    "\n",
    "    ntrain = train.shape[0]\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True).reset_index(drop=False)\n",
    "\n",
    "    train_test['m1'] = train_test[ID_COLUMN].diff().fillna(9999999).astype(int)\n",
    "    train_test['m2'] = train_test[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)\n",
    "\n",
    "    train_test = train_test.sort_values(by=['StartTime', 'Id'], ascending=True)\n",
    "    \n",
    "    train_test['m3'] = train_test[ID_COLUMN].diff().fillna(9999999).astype(int)\n",
    "    train_test['m4'] = train_test[ID_COLUMN].iloc[::-1].diff().fillna(9999999).astype(int)\n",
    "\n",
    "    train_test = train_test.sort_values(by=['index']).drop(['index'], axis=1)\n",
    "\n",
    "    train = train_test.iloc[:ntrain, :]\n",
    "    \n",
    "    test  = train_test.iloc[ntrain:, :]\n",
    "\n",
    "    features = np.setdiff1d(list(train.columns), [TARGET_COLUMN])\n",
    "    train=train[features]\n",
    "    \n",
    "    test=test[features]\n",
    "    \n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write to save time cost\n",
    "tr,te= magic_feature()\n",
    "tr.to_csv('Y://Data//Kaggle//bosch//magic_feature_tr_1104.csv',index=False)\n",
    "te.to_csv('Y://Data//Kaggle//bosch//magic_feature_te_1104.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniq_ctg(s):\n",
    "    n=len(s.unique())\n",
    "    return n\n",
    "\n",
    "def ctg_self_feature():\n",
    "    \n",
    "    DATA_DIR = \"Y://Data//Kaggle//bosch\"\n",
    "\n",
    "    ID_COLUMN = 'Id'\n",
    "    TARGET_COLUMN = 'Response'\n",
    "\n",
    "    SEED = 0\n",
    "    CHUNKSIZE = 51500\n",
    "    NROWS_TR = 1183747\n",
    "    NROWS_TE = 1183748\n",
    "\n",
    "    TRAIN_NUMERIC = \"{0}/train_numeric.csv\".format(DATA_DIR)\n",
    "    TRAIN_CTG = \"{0}/train_categorical.csv\".format(DATA_DIR)\n",
    "    TEST_NUMERIC = \"{0}/test_numeric.csv\".format(DATA_DIR)\n",
    "\n",
    "\n",
    "    TEST_CTG = \"{0}/test_categorical.csv\".format(DATA_DIR)\n",
    "\n",
    "\n",
    "    FILENAME = \"etimelhoods\"\n",
    "\n",
    "    train = pd.read_csv(TRAIN_NUMERIC, usecols=[ID_COLUMN], nrows=NROWS_TR)\n",
    "    test = pd.read_csv(TEST_NUMERIC, usecols=[ID_COLUMN], nrows=NROWS_TE)\n",
    "\n",
    "    train[\"No_NaN\"] = -1\n",
    "    train[\"uniqv\"]= -1\n",
    "    test[\"No_NaN\"] = -1\n",
    "    test[\"uniqv\"]= -1\n",
    "\n",
    "    for tr in pd.read_csv(TRAIN_CTG, chunksize=CHUNKSIZE, low_memory=False):\n",
    "\n",
    "        #feats = np.setdiff1d(tr.columns, [ID_COLUMN])\n",
    "        nonan= tr.count(axis=1).tolist()\n",
    "        #uniq=tr.apply(pd.Series.nunique,axis=1).tolist()\n",
    "        uniq= tr.apply(uniq_ctg, axis=1).tolist()\n",
    "\n",
    "        train.loc[train.Id.isin(tr.Id), 'No_NaN'] = nonan\n",
    "        \n",
    "        train.loc[train.Id.isin(tr.Id), 'uniqv'] = uniq\n",
    "        print(1)\n",
    "        \n",
    "\n",
    "            \n",
    "    for  te in pd.read_csv(TEST_CTG, chunksize=CHUNKSIZE,low_memory=False):\n",
    "\n",
    "        #feats = np.setdiff1d(tr.columns, [ID_COLUMN])\n",
    "\n",
    "        nonan1 = te.count(axis=1).tolist()\n",
    "        #etime_te = te[feats].max(axis=1).values\n",
    "        \n",
    "        uniq= te.apply(uniq_ctg, axis=1).tolist()\n",
    "\n",
    "        test.loc[test.Id.isin(te.Id), 'No_NaN'] = nonan1\n",
    "        test.loc[test.Id.isin(te.Id), 'uniqv'] = uniq\n",
    "        \n",
    "        print(2)\n",
    "\n",
    " \n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
